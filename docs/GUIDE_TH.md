# ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö LLM Proxy Server (‡∏â‡∏ö‡∏±‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î)

‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ô‡∏µ‡πâ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö LLM Proxy Server ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Connection ‡πÑ‡∏õ‡∏¢‡∏±‡∏á AI Provider ‡πÄ‡∏à‡πâ‡∏≤‡∏î‡∏±‡∏á‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î

---

## üèó System Architecture (‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö)

‡πÅ‡∏ú‡∏ô‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏°‡∏∑‡πà‡∏≠ Client (‡πÄ‡∏ä‡πà‡∏ô Python Script, cURL) ‡∏™‡πà‡∏á Request ‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡∏¢‡∏±‡∏á Proxy:

```mermaid
%%{init: {'theme':'base', 'themeVariables': { 'primaryColor':'#1f77b4', 'primaryBorderColor':'#004a9e', 'lineColor':'#666', 'secondColor':'#2ca02c', 'tertiaryColor':'#ff7f0e'}, 'flowchart': {'useMaxWidth': true, 'padding': '20', 'fontSize': '14'}}}%%
flowchart TD
    Client["üë§ Client App / SDK<br/>(Python, Node.js, cURL)"]
    
    Client -->|"üì§ HTTP Request<br/>(Auth: Bearer Virtual-Key)"| Proxy["üîê GO Proxy Server<br/><br/>Port 8132"]
    
    subgraph ProxyLogic["<b>‚öôÔ∏è Proxy Server Logic</b>"]
        Proxy -->|"1Ô∏è‚É£ Validate Key"| DB[("üíæ Database<br/>MongoDB/SQL<br/><br/>Stores Keys,<br/>Assignments")]
        DB -->|"‚úÖ Return Virtual Key Data"| Proxy
        
        Proxy -->|"2Ô∏è‚É£ Check Assignment"| Logic["üîÄ Routing Logic<br/><br/>Maps Virtual Model<br/>‚Üí Real Model"]
        Logic -->|"üìã Lookup Config"| DB
        
        Proxy -->|"3Ô∏è‚É£ Rate Limiting"| RateLimiter["‚è±Ô∏è Token Bucket<br/>Limiter<br/><br/>TPS Control"]
        RateLimiter -->|"‚úÖ OK"| Adapter["üîÑ Protocol Adapter<br/><br/>Transform to Provider<br/>Format"]
        RateLimiter -->|"‚õî Exceeded"| Reject["‚ö†Ô∏è 429<br/>Too Many<br/>Requests"]
    end

    subgraph AdapterLogic["<b>üåê Adapter Logic</b>"]
        Adapter -->|"Detect Provider"| Azure{"‚òÅÔ∏è Azure<br/>OpenAI?"}
        Adapter -->|"Detect Provider"| Google{"üîç Google<br/>Vertex/Studio?"}
        Adapter -->|"Detect Provider"| Standard{"üìå OpenAI/<br/>AWS?"}

        Azure -->|"‚úèÔ∏è Inject: api-key<br/>Rewrite: URL + version"| AzureEP["‚òÅÔ∏è Azure OpenAI<br/>Endpoint<br/><br/>https://xxx.openai.azure.com"]
        Google -->|"‚úèÔ∏è Inject: x-goog-api-key<br/>Strip: Bearer (if API key)"| GoogleEP["üîç Google Vertex/Studio<br/>Endpoint<br/><br/>aiplatform.googleapis.com"]
        Standard -->|"‚úèÔ∏è Inject: Bearer Token"| StandardEP["üìå OpenAI / AWS Bedrock<br/>Endpoint<br/><br/>api.openai.com"]
    end

    AzureEP -->|"üì• Response"| Client
    GoogleEP -->|"üì• Response"| Client
    StandardEP -->|"üì• Response"| Client
    Reject -->|"‚ùå Error"| Client
    
    style Client fill:#e1f5ff,stroke:#01579b,stroke-width:2px,color:#000
    style Proxy fill:#fff3e0,stroke:#e65100,stroke-width:3px,color:#000,font-weight:bold
    style DB fill:#f3e5f5,stroke:#4a148c,stroke-width:2px,color:#000
    style Logic fill:#e8f5e9,stroke:#1b5e20,stroke-width:2px,color:#000
    style RateLimiter fill:#fce4ec,stroke:#880e4f,stroke-width:2px,color:#000
    style Adapter fill:#fff9c4,stroke:#f57f17,stroke-width:2px,color:#000
    style Reject fill:#ffebee,stroke:#b71c1c,stroke-width:2px,color:#000
    style Azure fill:#e3f2fd,stroke:#1565c0,stroke-width:2px,color:#000
    style Google fill:#f1f8e9,stroke:#558b2f,stroke-width:2px,color:#000
    style Standard fill:#ede7f6,stroke:#512da8,stroke-width:2px,color:#000
    style AzureEP fill:#bbdefb,stroke:#0d47a1,stroke-width:2px,color:#000
    style GoogleEP fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px,color:#000
    style StandardEP fill:#d1c4e9,stroke:#3949ab,stroke-width:2px,color:#000
    style ProxyLogic fill:#fff8e1,stroke:#f57c00,stroke-width:2px
    style AdapterLogic fill:#f1f8e9,stroke:#689f38,stroke-width:2px
```

### ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏´‡∏•‡∏±‡∏Å (Components)
1.  **Proxy Handler (`internal/proxy`)**: ‡∏î‡πà‡∏≤‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ö HTTP Request ‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà:
    -   ‡πÅ‡∏Å‡∏∞ `Authorization` Header ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤ Virtual Key
    -   ‡∏≠‡πà‡∏≤‡∏ô Body ‡∏´‡∏£‡∏∑‡∏≠ URL Path ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏ß‡πà‡∏≤ User ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Model ‡∏≠‡∏∞‡πÑ‡∏£ (‡πÄ‡∏ä‡πà‡∏ô `gpt-4`, `gemini-1.5`)
2.  **Database (`internal/db`)**: ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 4 ‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏Å:
    -   `Connections`: ‡πÄ‡∏Å‡πá‡∏ö Credential ‡∏à‡∏£‡∏¥‡∏á‡∏Ç‡∏≠‡∏á Provider (‡πÄ‡∏ä‡πà‡∏ô OpenAI API Key) **(‡∏ñ‡∏π‡∏Å‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡∏´‡∏±‡∏™‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ)**
    -   `ProviderModels`: ‡πÄ‡∏Å‡πá‡∏ö‡∏ä‡∏∑‡πà‡∏≠ Model ‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö Provider (‡πÄ‡∏ä‡πà‡∏ô `gemini-1.5-flash-001`)
    -   `VirtualKeys`: ‡∏Å‡∏∏‡∏ç‡πÅ‡∏à‡∏ó‡∏µ‡πà Proxy ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏à‡∏Å‡∏à‡πà‡∏≤‡∏¢‡πÉ‡∏´‡πâ Client
    -   `Assignments`: ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏ß‡πà‡∏≤ Virtual Key ‡∏ô‡∏µ‡πâ ‡∏°‡∏µ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡πÉ‡∏ä‡πâ Model ‡πÑ‡∏´‡∏ô‡πÑ‡∏î‡πâ‡∏ö‡πâ‡∏≤‡∏á
3.  **Rate Limiter (`internal/ratelimit`)**: ‡∏Ñ‡∏≠‡∏¢‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Request ‡πÅ‡∏•‡∏∞ Token ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡πÑ‡∏õ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏à‡∏∞‡∏ï‡∏µ‡∏Å‡∏•‡∏±‡∏ö‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
4.  **Protocol Adapter**: (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å) ‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á Request ‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡πà‡∏≤‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô:
    -   **Azure**: ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏¥‡∏° `?api-version=...` ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ Header `api-key`
    -   **Google Vertex/Gemini**: ‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏•‡∏±‡∏ö‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á `x-goog-api-key` ‡∏´‡∏£‡∏∑‡∏≠ `Authorization: Bearer` ‡∏ï‡∏≤‡∏°‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡∏≠‡∏á Key ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ

---

## üõ† ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Connection ‡πÑ‡∏õ‡∏¢‡∏±‡∏á Provider ‡∏ï‡πà‡∏≤‡∏á‡πÜ

‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏±‡∏ô Server ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á:
```bash
# ‡∏£‡∏±‡∏ô‡∏ú‡πà‡∏≤‡∏ô Docker Compose
docker compose up -d

# ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏±‡∏ô Binary
./llm-proxy serve
```

### 1. OpenAI (Standard)
OpenAI ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏á‡πà‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î

**‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°:**
-   **API Key**: `sk-...`
-   **Endpoint**: `https://api.openai.com`

**‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á:**
```bash
# 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Connection
./llm-proxy connection add \
  --name "OpenAI-Main" \
  --provider "openai" \
  --endpoint "https://api.openai.com" \
  --api-key "sk-proj-YourKey..."

# (‡∏™‡∏°‡∏°‡∏ï‡∏¥‡πÑ‡∏î‡πâ ID: conn-123)

# 2. ‡πÄ‡∏û‡∏¥‡πà‡∏° Model ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô Connection ‡∏ô‡∏µ‡πâ
./llm-proxy model add \
  --conn-id "conn-123" \
  --name "gpt-4-turbo" \
  --remote "gpt-4-turbo-preview"
```

### 2. Azure OpenAI Service
Azure ‡∏°‡∏µ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö URL ‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏ß‡πà‡∏≤ ‡πÇ‡∏î‡∏¢‡∏°‡∏±‡∏Å‡∏à‡∏∞‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ `https://{resource}.openai.azure.com/` ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Foundry

**‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°:**
-   **API Key**: Key ‡∏à‡∏≤‡∏Å Azure Portal
-   **Endpoint**: URL ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì `https://my-resource.openai.azure.com` ‡∏´‡∏£‡∏∑‡∏≠ Foundry URL

**‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á:**
```bash
# 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Connection
./llm-proxy connection add \
  --name "Azure-Corp" \
  --provider "azure" \
  --endpoint "https://my-company.openai.azure.com" \
  --api-key "your-azure-key"

# (‡∏™‡∏°‡∏°‡∏ï‡∏¥‡πÑ‡∏î‡πâ ID: conn-456)

# 2. ‡πÄ‡∏û‡∏¥‡πà‡∏° Model (Deployment Name ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡πÉ‡∏ô Azure)
./llm-proxy model add \
  --conn-id "conn-456" \
  --name "gpt-4o" \
  --remote "gpt-4o" \
  --deployment "deployment-name-in-azure"
```

> **Note:** Proxy ‡∏à‡∏∞‡πÄ‡∏ï‡∏¥‡∏° `?api-version=2024-05-01-preview` ‡πÉ‡∏´‡πâ‡πÄ‡∏≠‡∏á‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡∏°‡∏≤

### 3. Google Gemini (AI Studio)
‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ Google AI Studio (API Key ‡∏õ‡∏Å‡∏ï‡∏¥)

**‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°:**
-   **API Key**: Key ‡∏à‡∏≤‡∏Å aistudio.google.com
-   **Endpoint**: `https://generativelanguage.googleapis.com`

**‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á:**
```bash
# 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Connection
./llm-proxy connection add \
  --name "Gemini-AIStudio" \
  --provider "google" \
  --endpoint "https://generativelanguage.googleapis.com" \
  --api-key "AIzaSy..."

# (‡∏™‡∏°‡∏°‡∏ï‡∏¥‡πÑ‡∏î‡πâ ID: conn-789)

# 2. ‡πÄ‡∏û‡∏¥‡πà‡∏° Model
./llm-proxy model add \
  --conn-id "conn-789" \
  --name "gemini-1.5-flash" \
  --remote "gemini-1.5-flash"
```

### 4. Google Vertex AI (Enterprise)
‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ Vertex AI ‡∏ö‡∏ô Google Cloud

**‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°:**
-   **API Key**: Service Account Key ‡∏´‡∏£‡∏∑‡∏≠ API Key (‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ `AQ.`) ‡∏´‡∏£‡∏∑‡∏≠ OAuth Token
-   **Endpoint**: `https://aiplatform.googleapis.com`

**‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á:**
```bash
# 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Connection
./llm-proxy connection add \
  --name "Vertex-Prod" \
  --provider "google" \
  --endpoint "https://aiplatform.googleapis.com" \
  --api-key "AQ.Ab8..." # ‡∏´‡∏£‡∏∑‡∏≠ OAuth Token

# (‡∏™‡∏°‡∏°‡∏ï‡∏¥‡πÑ‡∏î‡πâ ID: conn-999)

# 2. ‡πÄ‡∏û‡∏¥‡πà‡∏° Model
./llm-proxy model add \
  --conn-id "conn-999" \
  --name "gemini-3-flash" \
  --remote "gemini-3-flash-preview"
```

---

## üîë ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ù‡∏±‡πà‡∏á Client (Usage)

‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ connection ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ù‡∏±‡πà‡∏á Client ‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥ 2 ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ:

1.  **‡∏™‡∏£‡πâ‡∏≤‡∏á Virtual Key** (Admin ‡∏ó‡∏≥‡πÉ‡∏´‡πâ):
    ```bash
    ./llm-proxy vkey add --name "Frontend-App" --key "vk-front-1234"
    ```
2.  **‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå (Assign)** ‡∏ß‡πà‡∏≤ Key ‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ Model ‡πÑ‡∏´‡∏ô‡πÑ‡∏î‡πâ‡∏ö‡πâ‡∏≤‡∏á:
    ```bash
    # ‡∏ú‡∏π‡∏Å Virtual Key ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö Model ID ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ß‡πâ‡∏Ç‡πâ‡∏≤‡∏á‡∏ö‡∏ô
    ./llm-proxy assign \
      --vkey-id "vkey-id..." \
      --model-id "model-id..." \
      --alias "gpt-4" \
      --tps 50 # ‡∏¢‡∏¥‡∏á‡πÑ‡∏î‡πâ 50 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ï‡πà‡∏≠‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
    ```

### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Code (Python)

#### 1. ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ú‡πà‡∏≤‡∏ô OpenAI SDK (‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô)
‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏ä‡πâ Model ‡∏≠‡∏¢‡πà‡∏≤‡∏á GPT-4 ‡∏´‡∏£‡∏∑‡∏≠ Gemini ‡∏ó‡∏µ‡πà Config ‡πÄ‡∏õ‡πá‡∏ô OpenAI-Compatible:

```python
from openai import OpenAI

client = OpenAI(
    api_key="vk-front-1234",          # ‡πÉ‡∏ä‡πâ Virtual Key ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å Proxy
    base_url="http://localhost:8132/v1"  # ‡∏ä‡∏µ‡πâ‡∏°‡∏≤‡∏ó‡∏µ‡πà Proxy Server (‡πÄ‡∏ï‡∏¥‡∏° /v1)
)

response = client.chat.completions.create(
    model="gpt-4", # ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠ Alias ‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏ß‡πâ‡∏ï‡∏≠‡∏ô Assign
    messages=[{"role": "user", "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ!"}]
)

print(f"OpenAI Output: {response.choices[0].message.content}")
```

#### 2. ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ú‡πà‡∏≤‡∏ô Google Generative AI SDK (Native)
‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡∏≠‡∏á Gemini ‡πÄ‡∏ä‡πà‡∏ô **Thinking Config** ‡∏Ç‡∏≠‡∏á Gemini 2.0/3.0:

```python
import google.generativeai as genai

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏ä‡∏µ‡πâ‡∏°‡∏≤‡∏ó‡∏µ‡πà Proxy
genai.configure(
    api_key="vk-front-1234",
    client_options={
        "api_endpoint": "http://localhost:8132" # ‡∏ä‡∏µ‡πâ‡∏°‡∏≤‡∏ó‡∏µ‡πà Proxy
    },
    transport="rest" # ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ REST transport ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
)

model = genai.GenerativeModel("gemini-3-flash")

# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Thinking Config
response = model.generate_content(
    "‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á Quantum Physics ‡∏™‡∏±‡πâ‡∏ô‡πÜ",
    generation_config={
        "thinking_config": {"include_thoughts": True}
    }
)

print(f"Gemini Output: {response.text}")
```

#### 3. ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ú‡πà‡∏≤‡∏ô Azure OpenAI SDK
‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡πâ‡∏ô‡πÄ‡∏Ñ‡∏¢‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏≠‡∏á Azure SDK:

```python
from openai import AzureOpenAI

client = AzureOpenAI(
    api_key="vk-front-1234",
    api_version="2024-05-01-preview", # ‡∏´‡∏£‡∏∑‡∏≠ version ‡∏≠‡∏∑‡πà‡∏ô‡πÜ
    azure_endpoint="http://localhost:8132" # ‡∏ä‡∏µ‡πâ‡∏°‡∏≤‡∏ó‡∏µ‡πà Proxy
)

# ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: 'model' ‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠ Deployment Name ‡∏´‡∏£‡∏∑‡∏≠ Alias ‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏ô Proxy
response = client.chat.completions.create(
    model="azure-gpt-4o",
    messages=[{"role": "user", "content": "Hello Azure!"}]
)

print(f"Azure Output: {response.choices[0].message.content}")
```

#### 4. ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ú‡πà‡∏≤‡∏ô LangChain
LangChain ‡∏ô‡∏¥‡∏¢‡∏°‡∏°‡∏≤‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á LLM App:

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model="gemini-3-flash",
    openai_api_key="vk-front-1234",
    openai_api_base="http://localhost:8132/v1", # ‡∏ä‡∏µ‡πâ‡∏°‡∏≤‡∏ó‡∏µ‡πà Proxy
    temperature=0
)

response = llm.invoke("‡πÄ‡∏•‡πà‡∏≤‡∏ô‡∏¥‡∏ó‡∏≤‡∏ô‡πÉ‡∏´‡πâ‡∏ü‡∏±‡∏á‡∏´‡∏ô‡πà‡∏≠‡∏¢")
print(f"LangChain Output: {response.content}")
```
